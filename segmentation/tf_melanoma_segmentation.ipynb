{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.contrib.slim.nets import resnet_v1\n",
    "import datetime, os, glob, errno\n",
    "from tensorflow.python.platform import tf_logging as logging\n",
    "\n",
    "\n",
    "def parser(record):\n",
    "  \"\"\"Parses input records and returns batch_size samples\n",
    "  \"\"\"\n",
    "  \n",
    "  # each tf.Example object in input .tfrecords file packs image and label as,\n",
    "  # dictionary with key: 'image', its value: a png-encoded bytearray representation\n",
    "  # dictionary with key: 'label', its value: a png-encoded bytearray representation,\n",
    "  # label is a binary image with 255 pixel value for foreground, 0 for background.\n",
    "  keys_to_features = {\n",
    "      \"image\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "      \"label\": tf.FixedLenFeature((), tf.string, default_value=\"\")\n",
    "  }\n",
    "  \n",
    "  parsed = tf.parse_single_example(record, keys_to_features)\n",
    "  \n",
    "  # input image is a 3-channel RGB image\n",
    "  decoded_image = tf.image.decode_png(parsed[\"image\"], channels=3)\n",
    "  \n",
    "  # input label is a grayscale image\n",
    "  decoded_label = tf.image.decode_png(parsed[\"label\"], channels=1)\n",
    "   \n",
    "  # turn the label to floating-point with [0,1) range.\n",
    "  decoded_label = tf.image.convert_image_dtype(decoded_label, tf.float32)\n",
    "  #decoded_label = tf.round(decoded_label)\n",
    "  decoded_label = tf.to_int32(decoded_label)\n",
    "  \n",
    "  # drop the last dimension to get shape (H,W) instead of (H,W,1)\n",
    "  #decoded_label = tf.squeeze(decoded_label, axis=[2])\n",
    "  \n",
    "  # repeat along the last dimension\n",
    "  decoded_label = tf.concat([decoded_label, 1-decoded_label], axis=2) \n",
    "  ch0, ch1 = tf.split(value=decoded_label, num_or_size_splits=2, axis=2)\n",
    "  decoded_label = tf.concat(values=[ch1, ch0], axis=2)\n",
    "  \n",
    "  # per-channel mean values are taken from:\n",
    "  # https://github.com/yulequan/melanoma-recognition/blob/master/segmentation/ResNet-50-f8s-skin-train-val.prototxt\n",
    "  mean = tf.constant([184., 153., 138.],\n",
    "                     dtype=tf.float32, shape=[1, 1, 3], name='img_mean')\n",
    "  \n",
    "  # center the image with per-channel RGB mean\n",
    "  decoded_image = tf.to_float(decoded_image)\n",
    "  im_centered = decoded_image - mean\n",
    "  #return (im_centered, decoded_label)\n",
    "  \n",
    "  #im_centered = tf.image.per_image_standardization(decoded_image)\n",
    "        \n",
    "  imagedict = {'image': im_centered}\n",
    "  labeldict = {'label': decoded_label}\n",
    "  \n",
    "  return im_centered, decoded_label \n",
    "\n",
    "      \n",
    "\n",
    "def preproc_train(sample, target):\n",
    "  \n",
    "  seed = np.random.randint(0, 2**32)\n",
    "  \n",
    "  cropsize_img = [480, 480, 3]\n",
    "  cropsize_label = [480, 480, 2]\n",
    "  \n",
    "  image = tf.random_crop(sample, cropsize_img, seed=seed, name='crop_mirror_train_img')\n",
    "  label = tf.random_crop(target, cropsize_label, seed=seed, name='crop_mirror_train_label')\n",
    "  \n",
    "  tf.summary.image('crop_mirror_train_img', image)\n",
    "  tf.summary.image('crop_mirror_train_label', tf.cast(label,dtype=tf.uint8))\n",
    "  \n",
    "  image = tf.image.random_flip_left_right(image, seed=seed)\n",
    "  label =  tf.image.random_flip_left_right(label, seed=seed)\n",
    "\n",
    "  return image, label\n",
    "\n",
    "\n",
    "def preproc_val(sample, target):\n",
    "  \n",
    "  seed = np.random.randint(0, 2**32)\n",
    "  \n",
    "  image = tf.image.resize_image_with_crop_or_pad(sample, 480, 480)\n",
    "  label = tf.image.resize_image_with_crop_or_pad(target, 480, 480)  \n",
    "  \n",
    "  image = tf.image.random_flip_left_right(image, seed=seed)\n",
    "  label =  tf.image.random_flip_left_right(label, seed=seed)\n",
    "\n",
    "  return image, label\n",
    "\n",
    "  \n",
    "def my_input_fn_train(filename, batch_size, epochs):\n",
    "  \"\"\" reads the .tfrecords file,\n",
    "  process data using parser method,\n",
    "  shuffles data and returns the next batch.\n",
    "  \n",
    "  instantiates a tf.Dataset object and obtains a tf.data.Iterator, \n",
    "  that throws outOfRangeError when next batch goes out of the given epoch limit.\n",
    "  more info: https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "  \"\"\"\n",
    "\n",
    "  dataset = tf.data.TFRecordDataset([filename])\n",
    "  augmented = dataset.map(parser\n",
    "  ).map(\n",
    "      preproc_train\n",
    "  ).shuffle(\n",
    "      buffer_size=1000\n",
    "  ).batch(\n",
    "      batch_size\n",
    "  ).repeat(\n",
    "      epochs\n",
    "  )\n",
    "  \n",
    "  # this returns the next batch from the parser function\n",
    "  # the returned tuple is a dictionary for image and a dictionary for labels\n",
    "  features, labels = augmented.make_one_shot_iterator().get_next()\n",
    "  return {'image': features}, {'label': labels} \n",
    "\n",
    "\n",
    "def my_input_fn_val(filename, batch_size, epochs):\n",
    "  \"\"\" reads the .tfrecords file,\n",
    "  process data using parser method,\n",
    "  shuffles data and returns the next batch.\n",
    "  \n",
    "  instantiates a tf.Dataset object and obtains a tf.data.Iterator, \n",
    "  that throws outOfRangeError when next batch goes out of the given epoch limit.\n",
    "  more info: https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "  \"\"\"\n",
    "  \n",
    "  dataset = tf.data.TFRecordDataset([filename])\n",
    "  augmented = dataset.map(parser\n",
    "  ).map(\n",
    "      preproc_val\n",
    "  ).batch(\n",
    "      batch_size\n",
    "  ).repeat(\n",
    "      epochs\n",
    "  )\n",
    "  \n",
    "  # this returns the next batch from the parser function\n",
    "  # the returned tuple is a dictionary for image and a dictionary for labels\n",
    "  features, labels = augmented.make_one_shot_iterator().get_next()\n",
    "  return {'image': features}, {'label': labels} \n",
    "          \n",
    "          \n",
    "    \n",
    "def get_deconv_filter(f_shape):\n",
    "  \"\"\"initialize a bilinear interpolation filter with\n",
    "  given shape.\n",
    "  \n",
    "  this filter values are trained and updated in the current computation graph.\n",
    "  \"\"\"\n",
    "  width = f_shape[0]\n",
    "  heigh = f_shape[0]\n",
    "  f = np.ceil(width/2.0)\n",
    "  c = (2 * f - 1 - f % 2) / (2.0 * f)\n",
    "  bilinear = np.zeros([f_shape[0], f_shape[1]])\n",
    "  for x in range(width):\n",
    "    for y in range(heigh):\n",
    "      value = (1 - abs(x / f - c)) * (1 - abs(y / f - c))\n",
    "      bilinear[x, y] = value\n",
    "  weights = np.zeros(f_shape)\n",
    "  for i in range(f_shape[2]):\n",
    "    weights[:, :, i, i] = bilinear\n",
    "\n",
    "  init = tf.constant_initializer(value=weights,\n",
    "                                 dtype=tf.float32)\n",
    "  var = tf.get_variable(name=\"up_filter\",\n",
    "                        initializer=init,\n",
    "                        shape=weights.shape,\n",
    "                        regularizer=tf.contrib.layers.l2_regularizer(5e-4))\n",
    "  return var\n",
    "\n",
    "\n",
    "\n",
    "def upscore_layer(x, shape, num_classes, name, ksize, stride):\n",
    "  \"\"\"transposed convolution filter to learn upsampling filter values.\n",
    "  Given a feature map x, initialize a bilinear interpolation filter with\n",
    "  given shape to upsample the map based on the given stride.\n",
    "  \n",
    "  this filter values are trained and updated in the current computation graph.\n",
    "  \"\"\"   \n",
    "  strides = [1, stride, stride, 1]\n",
    "  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
    "    in_features = x.get_shape()[3].value\n",
    "    if shape is None:\n",
    "      in_shape = tf.shape(x)\n",
    "      h = ((in_shape[1] - 1) * stride) + 1\n",
    "      w = ((in_shape[2] - 1) * stride) + 1\n",
    "      new_shape = [in_shape[0], h, w, num_classes]\n",
    "    else:\n",
    "      new_shape = [shape[0], shape[1], shape[2], num_classes]\n",
    "    \n",
    "    output_shape = tf.stack(new_shape)\n",
    "    f_shape = [ksize, ksize, num_classes, in_features]\n",
    "    \n",
    "    weights = get_deconv_filter(f_shape)\n",
    "\n",
    "    #grp1 = tf.nn.conv2d_transpose(x[:, :, :, :int(in_features/2)], weights[:, :, 0, :], tf.stack([shape[0], shape[1], shape[2], 1]), strides = strides, padding='SAME')\n",
    "    #grp2 = tf.nn.conv2d_transpose(x[:, :, :, int(in_features/2):], weights[:, :, 1, :], tf.stack([shape[0], shape[1], shape[2], 1]), strides = strides, padding='SAME')\n",
    "    \n",
    "    #deconv = tf.concat(axis=3, values=[grp1, grp2])\n",
    "    \n",
    "    deconv = tf.nn.conv2d_transpose(x, weights, output_shape, strides = strides, padding='SAME')\n",
    "    \n",
    "    return deconv\n",
    "\n",
    "  \n",
    "  \n",
    "def score_layer(x, name, num_classes, stddev = 0.001): \n",
    "  \"\"\"receives a feature map and trains a linear scoring filter Wx+b\n",
    "  \n",
    "  this result with a new feature map with a consistent shape to be fused (per-pixel addition)\n",
    "  with the corresponding upsampling result from the same input feature map x.\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(name, reuse=tf.AUTO_REUSE) as scope:\n",
    "    # get number of input channels\n",
    "    in_features = x.get_shape()[3].value\n",
    "    shape = [1, 1, in_features, num_classes]\n",
    "    w_decay = 5e-4\n",
    "    #init = tf.truncated_normal_initializer(stddev = stddev)\n",
    "    init = tf.constant_initializer(0.0)\n",
    "    weights = tf.get_variable(\"weights\", \n",
    "                              shape = shape, \n",
    "                              initializer = init,\n",
    "                              regularizer=tf.contrib.layers.l2_regularizer(w_decay))\n",
    "    #collection_name = tf.GraphKeys.REGULARIZATION_LOSSES\n",
    "\n",
    "    #if not tf.get_variable_scope().reuse:\n",
    "    #  weight_decay = tf.multiply(tf.nn.l2_loss(weights), w_decay, name='weight_loss')\n",
    "    #  tf.add_to_collection(collection_name, weight_decay)\n",
    "\n",
    "    conv = tf.nn.conv2d(x, weights, [1, 1, 1, 1], padding='SAME')\n",
    "    \n",
    "    # Apply bias\n",
    "    initializer = tf.constant_initializer(0.0)\n",
    "    conv_biases = tf.get_variable(name='biases', shape=[num_classes], initializer = initializer)\n",
    "    bias = tf.nn.bias_add(conv, conv_biases)\n",
    "    \n",
    "    return bias     \n",
    "      \n",
    "  \n",
    "\n",
    "def resnet_v1_50_fcn(features, labels, mode, params):\n",
    "    \n",
    "    num_classes = params['num_classes']\n",
    "   \n",
    "    \n",
    "    # output_stride denotes the rate of downsampling in the resnet network,i.e.,\n",
    "    # 32 results with a feature map with a 1/32 downsampling rate such as,\n",
    "    # (224,224) input is decreased to (8,8) resolution. \n",
    "    # Then, the rest of the code starts upsampling from this output, until reaching\n",
    "    # the input resolution.\n",
    "    with slim.arg_scope(resnet_v1.resnet_arg_scope(weight_decay=0.0005)):\n",
    "      net, end_points = resnet_v1.resnet_v1_50(features['image'],\n",
    "                                             global_pool=False,\n",
    "                                             output_stride=32)\n",
    "    \n",
    "      scale5 = net\n",
    "      scale4 = end_points['resnet_v1_50/block3/unit_5/bottleneck_v1']\n",
    "      scale3 = end_points['resnet_v1_50/block2/unit_3/bottleneck_v1']\n",
    "      scale2 = end_points['resnet_v1_50/block1/unit_2/bottleneck_v1']\n",
    "      input_x = features['image']\n",
    "    \n",
    "    with tf.variable_scope('scale_fcn'):\n",
    "      \n",
    "      score_scale5 = score_layer(scale5, \"score_scale5\", num_classes = num_classes)\n",
    "      upscore2 = upscore_layer(score_scale5, shape = tf.shape(scale4), num_classes = num_classes, name = \"upscore2\", ksize = 4, stride = 2) \n",
    "      \n",
    "      score_scale4 = score_layer(scale4, \"score_scale4\", num_classes = num_classes)\n",
    "      fuse_scale4 = tf.add(upscore2, score_scale4)\n",
    "      \n",
    "      upscore4 = upscore_layer(fuse_scale4, shape = tf.shape(scale3), num_classes = num_classes, name = \"upscore4\", ksize = 4, stride = 2) \n",
    "      score_scale3 = score_layer(scale3, \"score_scale3\", num_classes = num_classes)\n",
    "      fuse_scale3 = tf.add(upscore4, score_scale3)\n",
    "      \n",
    "      upscore32 = upscore_layer(fuse_scale3, shape = tf.shape(input_x), num_classes = num_classes, name = \"upscore32\", ksize = 16, stride = 8)\n",
    "\n",
    "      pred_up = tf.argmax(upscore32, axis = 3)   # shape: [4 480 480]\n",
    "      pred = tf.expand_dims(pred_up, dim = 3, name='pred')  # shape: [4 480 480 1]  \n",
    "      \n",
    "#       sess = tf.Session()\n",
    "#       sess.run(tf.global_variables_initializer())\n",
    "#       sess.run(tf.local_variables_initializer())\n",
    "#       print(sess.run(tf.shape(scale5)))\n",
    "#       print(sess.run(tf.shape(upscore32)))\n",
    "#       print(sess.run(tf.shape(pred_up)))\n",
    "#       print(sess.run(tf.shape(pred)))\n",
    "#       sess.close()\n",
    "      \n",
    "    tf.summary.image('ground-truth', tf.expand_dims(255.0*tf.to_float(tf.argmax(labels['label'], axis = 3)), axis = 3))\n",
    "    tf.summary.image('prediction', 255.0*tf.to_float(pred))\n",
    "    \n",
    " \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_up)\n",
    "    \n",
    "    # Using tf.losses, any loss is added to the tf.GraphKeys.LOSSES collection\n",
    "    # We can then call the total loss easily    \n",
    "    tf.losses.softmax_cross_entropy(onehot_labels=labels['label'], \n",
    "                                    logits=upscore32)\n",
    "    loss = tf.losses.get_total_loss() \n",
    "    tf.summary.scalar('loss', loss)\n",
    "    \n",
    "\n",
    "    ## Compute evaluation metrics.\n",
    "    # compute mean intersection over union, which corresponds to JA metric in the paper.\n",
    "    iou_op, update_op = tf.metrics.mean_iou(\n",
    "      labels=tf.reshape(tf.argmax(labels['label'], axis = 3), [-1]),\n",
    "      num_classes=2,\n",
    "      predictions=tf.to_int32(tf.reshape(pred_up, [-1])), name=\"acc_op\")\n",
    "  \n",
    "    with tf.control_dependencies([update_op]):\n",
    "      iou = tf.identity(iou_op)\n",
    "      \n",
    "    tf.summary.scalar('iou', iou)   \n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode, loss=loss, eval_metric_ops={'iou': (iou_op, update_op)})\n",
    "    \n",
    "    # Create training op.\n",
    "    assert mode == tf.estimator.ModeKeys.TRAIN\n",
    "    \n",
    "    \n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    \n",
    "    training_loss = tf.identity(loss, name='training_loss')\n",
    "    \n",
    "    # set initial learning rate and \n",
    "    # scale it by 0.1 in every 3000 steps\n",
    "    # as stated in https://github.com/yulequan/melanoma-recognition/blob/master/segmentation/solver.prototxt\n",
    "    boundaries = [i*params['decay_steps'] for i in range(1, int(np.ceil(params['max_steps']/params['decay_steps']))) ]\n",
    "    boundaries[-1] = params['max_steps']\n",
    "    initial = [params['initial_learning_rate']]\n",
    "    values = initial + [params['initial_learning_rate']*(0.1**i) for i in range(1,len(boundaries)+1)]\n",
    "    lr = tf.train.piecewise_constant(global_step, boundaries, values)\n",
    "    #lr = tf.constant(params['initial_learning_rate'])\n",
    "    \n",
    "    tf.summary.scalar('lr', lr)\n",
    "    \n",
    "    # Variables that affect learning rate\n",
    "    var_resnet_batchnorm = [var for var in tf.trainable_variables() \n",
    "                            if ('conv1/BatchNorm' in var.name or \n",
    "                                'conv2/BatchNorm' in var.name or \n",
    "                                'conv3/BatchNorm' in var.name or \n",
    "                                'shortcut/BatchNorm' in var.name)] \n",
    "  \n",
    "    var_upscale = [var for var in tf.trainable_variables() \n",
    "                   if 'score' in var.name and 'bias' not in var.name]\n",
    "    \n",
    "    var_score_bias = [var for var in tf.trainable_variables() \n",
    "                      if 'score' in var.name and 'bias' in var.name]\n",
    " \n",
    "    var_rest = [var for var in tf.trainable_variables() \n",
    "                if var not in var_resnet_batchnorm + var_upscale + var_score_bias]\n",
    "    \n",
    "    # this is as stated in the paper and prototxt file,\n",
    "    # https://github.com/yulequan/melanoma-recognition/blob/master/segmentation/ResNet-50-f8s-skin-train-val.prototxt\n",
    "    # batchnorm variables placed just after each convolutional layer in each resnet block, are not updated.\n",
    "    # so we set zero learning for these variables\n",
    "    #opt1 = tf.train.MomentumOptimizer(0, 0.9)\n",
    "  \n",
    "    # this is also due to the prototxt file and the paper,\n",
    "    # scoring and upsampling filters receive 0.1 * learning rate\n",
    "    # https://github.com/yulequan/melanoma-recognition/blob/master/segmentation/ResNet-50-f8s-skin-train-val.prototxt\n",
    "    opt_upscale = tf.train.MomentumOptimizer(lr*0.1, 0.9)\n",
    "  \n",
    "    # rest of the variables receive the current learning rate\n",
    "    opt_scorebias = tf.train.MomentumOptimizer(lr*0.2, 0.9)\n",
    "  \n",
    "    # rest of the variables receive the current learning rate\n",
    "    opt_rest = tf.train.MomentumOptimizer(lr, 0.9)\n",
    "  \n",
    "    # gradient op: obtain the gradients with loss and given variables\n",
    "    grads = tf.gradients(loss, var_upscale + var_score_bias + var_rest)\n",
    "  \n",
    "    # grads for the first set of variables, currently has no effect due to zero learning rate.\n",
    "    #grads1 = grads[:len(var_resnet_batchnorm)]\n",
    "  \n",
    "    # grads for scoring and upsampling filters. Will get updated based on 0.1*learning_rate\n",
    "    grads_upscale = grads[:len(var_upscale)]\n",
    "  \n",
    "    #for i,val in enumerate(grads2):\n",
    "    #  tf.summary.histogram('upscale_grads_{}'.format(i), val)\n",
    "  \n",
    "    # grads for bias variables\n",
    "    grads_scorebias = grads[len(var_upscale):len(var_upscale)+len(var_score_bias)]\n",
    "    \n",
    "    # grads for the rest of variables\n",
    "    grads_rest = grads[len(var_upscale)+len(var_score_bias):]\n",
    "    \n",
    "  \n",
    "    #train_op1 = opt1.apply_gradients(zip(grads1, var_resnet_batchnorm), global_step=global_step)\n",
    "    train_op_upscale = opt_upscale.apply_gradients(zip(grads_upscale, var_upscale), global_step=global_step)\n",
    "    train_op_scorebias = opt_scorebias.apply_gradients(zip(grads_scorebias, var_score_bias), global_step=global_step)\n",
    "    train_op_rest = opt_rest.apply_gradients(zip(grads_rest, var_rest), global_step=global_step)\n",
    "\n",
    "    train_op = tf.group(train_op_upscale, train_op_scorebias, train_op_rest)\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "  \n",
    "  \n",
    "class MyLoggingAverageLossHook(tf.train.LoggingTensorHook):\n",
    "  \n",
    "  def __init__(self, tensors, every_n_iter):\n",
    "    super().__init__(tensors=tensors, every_n_iter=every_n_iter)\n",
    "    \n",
    "    # keep track of previous losses\n",
    "    self.losses=[]\n",
    "    self.every_n_iter=every_n_iter\n",
    "    \n",
    "    \n",
    "  def after_run(self, run_context, run_values):\n",
    "    _ = run_context\n",
    "    \n",
    "    self._tag = ''\n",
    "    \n",
    "    # please put only one loss tensor\n",
    "    for tag in self._tag_order:\n",
    "      self.losses.append(run_values.results[tag])\n",
    "      self._tag = tag    \n",
    "    \n",
    "    if self._should_trigger:\n",
    "      self._log_tensors(run_values.results)\n",
    "\n",
    "    self._iter_count += 1\n",
    "    \n",
    "  \n",
    "  def _log_tensors(self, tensor_values):\n",
    "    \n",
    "    if self._iter_count % self.every_n_iter == 0:\n",
    "      original = np.get_printoptions()\n",
    "      np.set_printoptions(suppress=True)\n",
    "      logging.info(\"%s = %s\" % (self._tag, np.mean(self.losses)))      \n",
    "      np.set_printoptions(**original)\n",
    "      self.losses=[]\n",
    "  \n",
    "\n",
    "  \n",
    "tf.reset_default_graph()\n",
    "\n",
    "# filename_train = 'melanoma_train_224.tfrecords'\n",
    "# filename_val = 'melanoma_val_224.tfrecords'\n",
    "filename_train = 'melanoma_train_v8.tfrecords'\n",
    "filename_val = 'melanoma_val_v8.tfrecords'\n",
    "save_model_dir='/tmp/log'\n",
    "restore_ckpt_path='/tmp/log/resnet_v1_50.ckpt'\n",
    "save_checkpoints_steps=3000\n",
    "params = {'initial_learning_rate' : 1e-3,\n",
    "          'num_classes' : 2,\n",
    "          'decay_steps' : 3000,\n",
    "          'max_steps' : 100000\n",
    "         }\n",
    "  \n",
    "  \n",
    "#with tf.Session() as sess:\n",
    "  \n",
    "# exclude_restore = [var.name for var in tf.global_variables() if not ('logits' in var.name or 'scale_fcn' in var.name or 'Momentum' in var.name) ] \n",
    "# variables_to_restore = slim.get_variables_to_restore(exclude=exclude_restore)\n",
    "# tf.train.init_from_checkpoint(restore_ckpt_path,\n",
    "#                                {v.name.split(':')[0]: v for v in variables_to_restore})\n",
    "  \n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "  \n",
    "        \n",
    "run_config = tf.estimator.RunConfig(save_checkpoints_steps=save_checkpoints_steps)\n",
    "  \n",
    "  \n",
    "avg_train_loss_log = {\"average_training_loss\": \"training_loss\"}\n",
    "  \n",
    "  # this custom logging hook is created to average last every_n_iter loss values\n",
    "  # and display the result as an INFO\n",
    "my_averageloss_logging_hook = MyLoggingAverageLossHook(\n",
    "      tensors=avg_train_loss_log,\n",
    "      every_n_iter=10)\n",
    "        \n",
    "ws = tf.estimator.WarmStartSettings(ckpt_to_initialize_from=restore_ckpt_path,\n",
    "                       vars_to_warm_start='.*resnet_v1.*')\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "            model_fn=resnet_v1_50_fcn,\n",
    "            model_dir=save_model_dir,\n",
    "            params=params,\n",
    "            config=run_config,\n",
    "            warm_start_from=ws\n",
    "        )\n",
    "\n",
    "print(estimator.eval_dir())\n",
    "\n",
    "print(os.listdir(save_model_dir))\n",
    "\n",
    "# train_spec = tf.estimator.TrainSpec(input_fn=lambda:my_input_fn(filename_train, batch_size=4, epochs=500), \n",
    "#                                       max_steps=params['max_steps'],\n",
    "#                                       hooks=[my_averageloss_logging_hook]) \n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=lambda:my_input_fn_train(filename_train, batch_size=4, epochs=500), \n",
    "                                      max_steps=params['max_steps']) \n",
    "  \n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=lambda:my_input_fn_val(filename_val, batch_size=4, epochs=1),\n",
    "                                 steps=None, throttle_secs=50)\n",
    "       \n",
    "tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "tf-melanoma-segmentation.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
