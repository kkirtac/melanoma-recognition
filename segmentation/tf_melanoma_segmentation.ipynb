{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf-melanoma-segmentation.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "HpxCu0TEy8wG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fMnMpcCZlaD_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dW_PfH9jDKHI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uazfgki-FdmO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tensorflow/models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IvLcWfoFDhYL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os,sys\n",
        "sys.path.append(\"/content/models/research/slim\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CyylG-8tDwA4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from datasets import dataset_utils\n",
        "import tensorflow as tf\n",
        "\n",
        "url = \"http://download.tensorflow.org/models/resnet_v1_50_2016_08_28.tar.gz\"\n",
        "\n",
        "# Specify where you want to download the model to\n",
        "checkpoints_dir = '/content'\n",
        "\n",
        "if not tf.gfile.Exists(checkpoints_dir):\n",
        "    tf.gfile.MakeDirs(checkpoints_dir)\n",
        "\n",
        "dataset_utils.download_and_uncompress_tarball(url, checkpoints_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CWHlfiRzF33A",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!rm -rf resnet_v1_50_2016_08_28.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F6KbLUQW0udx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir checkpoints"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5GrxVLIAzg3R",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# download training and validation data files\n",
        "validation_file_id = '1sepSrVG4_mnnmjlB-SAPorN4ksUN8jsq' \n",
        "\n",
        "downloaded = drive.CreateFile({'id': validation_file_id})\n",
        "\n",
        "print(downloaded[\"title\"], downloaded[\"mimeType\"])\n",
        "\n",
        "downloaded.GetContentFile(downloaded['title'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Gr3kGa2OuDW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "training_file_id = '1inW8VfAfSYykAGqyarpigA37rUBX4C_w'\n",
        "\n",
        "downloaded = drive.CreateFile({'id': training_file_id})\n",
        "\n",
        "print(downloaded[\"title\"], downloaded[\"mimeType\"])\n",
        "\n",
        "downloaded.GetContentFile(downloaded['title'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WfK5_EPPi6CC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "code"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow.contrib.slim as slim\n",
        "from tensorflow.contrib.slim.nets import resnet_v1\n",
        "\n",
        "\n",
        "\n",
        "def parser(record):\n",
        "  \"\"\"Parses input records and returns batch_size samples\n",
        "  \"\"\"\n",
        "  \n",
        "  # each tf.Example object in input .tfrecords file packs image and label as,\n",
        "  # dictionary with key: 'image', its value: a png-encoded bytearray representation\n",
        "  # dictionary with key: 'label', its value: a png-encoded bytearray representation,\n",
        "  # label is a binary image with 255 pixel value for foreground, 0 for background.\n",
        "  keys_to_features = {\n",
        "      \"image\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n",
        "      \"label\": tf.FixedLenFeature((), tf.string, default_value=\"\")\n",
        "  }\n",
        "  \n",
        "  parsed = tf.parse_single_example(record, keys_to_features)\n",
        "  \n",
        "  # input image is a 3-channel RGB image\n",
        "  decoded_image = tf.image.decode_png(parsed[\"image\"], channels=3)\n",
        "  #decoded_image = tf.image.resize_images(decoded_image, [224, 224])\n",
        "  \n",
        "  # input label is a grayscale image\n",
        "  decoded_label = tf.image.decode_png(parsed[\"label\"], channels=1)   \n",
        "  #decoded_label = tf.image.resize_images(decoded_label, [224, 224])\n",
        "  \n",
        "  decoded_image = tf.to_float(decoded_image)\n",
        "  \n",
        "  # turn the label to floating-point with [0,1) range.\n",
        "  decoded_label = tf.image.convert_image_dtype(decoded_label, tf.float32)\n",
        "  decoded_label = tf.to_int32(decoded_label)\n",
        "  \n",
        "  # drop the last dimension to get shape (H,W) instead of (H,W,1)\n",
        "  decoded_label = tf.squeeze(decoded_label, axis=[2])\n",
        "  \n",
        "  # repeat along the last dimension\n",
        "  #decoded_label = tf.concat([decoded_label, 1-decoded_label], axis=2) \n",
        "  \n",
        "  # per-channel mean values are taken from:\n",
        "  # https://github.com/yulequan/melanoma-recognition/blob/master/segmentation/ResNet-50-f8s-skin-train-val.prototxt\n",
        "  mean = tf.constant([182., 149., 135.],\n",
        "                     dtype=tf.float32, shape=[1, 1, 3], name='img_mean')\n",
        "  \n",
        "  # center the image with per-channel RGB mean\n",
        "  im_centered = decoded_image - mean\n",
        "  #return (im_centered, decoded_label)\n",
        "        \n",
        "  # return features(image batch) as a dictionary containing min and max intensity values\n",
        "  # return labels as a dictionary containing min and max intensity values\n",
        "  return {\"image\": im_centered, \n",
        "          \"min\":tf.reduce_min(tf.reduce_min(im_centered, axis=1), axis=0),\n",
        "          \"max\":tf.reduce_max(tf.reduce_max(im_centered, axis=1), axis=0)}, {\"label\": decoded_label, \n",
        "                                                                     \"min\":tf.reduce_min(tf.reduce_min(decoded_label, axis=1), axis=0),\n",
        "                                                                     \"max\":tf.reduce_max(tf.reduce_max(decoded_label, axis=1), axis=0)}\n",
        "      \n",
        "      \n",
        "def my_input_fn(filename, batch_size, epochs):\n",
        "  \"\"\" reads the .tfrecords file,\n",
        "  process data using parser method,\n",
        "  shuffles data and returns the next batch.\n",
        "  \n",
        "  instantiates a tf.Dataset object and obtains a tf.data.Iterator, \n",
        "  that throws outOfRangeError when next batch goes out of the given epoch limit.\n",
        "  more info: https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
        "  \"\"\"\n",
        "  \n",
        "  dataset = tf.data.TFRecordDataset(\n",
        "      [filename]\n",
        "  ).map(\n",
        "      parser\n",
        "  ).shuffle(\n",
        "      buffer_size=100\n",
        "  ).batch(\n",
        "      batch_size\n",
        "  ).repeat(\n",
        "      epochs\n",
        "  )\n",
        "  \n",
        "  # this returns the next batch from the parser function\n",
        "  # the returned tuple is a dictionary for image and a dictionary for labels\n",
        "  return dataset.make_one_shot_iterator().get_next() \n",
        "          \n",
        "          \n",
        "def get_deconv_filter(f_shape):\n",
        "  \"\"\"initialize a bilinear interpolation filter with\n",
        "  given shape.\n",
        "  \n",
        "  this filter values are trained and updated in the current computation graph.\n",
        "  \"\"\"\n",
        "  width = f_shape[0]\n",
        "  heigh = f_shape[0]\n",
        "  f = np.ceil(width/2.0)\n",
        "  c = (2 * f - 1 - f % 2) / (2.0 * f)\n",
        "  bilinear = np.zeros([f_shape[0], f_shape[1]])\n",
        "  for x in range(width):\n",
        "      for y in range(heigh):\n",
        "          value = (1 - abs(x / f - c)) * (1 - abs(y / f - c))\n",
        "          bilinear[x, y] = value\n",
        "  weights = np.zeros(f_shape)\n",
        "  for i in range(f_shape[2]):\n",
        "      weights[:, :, i, i] = bilinear\n",
        "\n",
        "  init = tf.constant_initializer(value=weights,\n",
        "                                 dtype=tf.float32)\n",
        "  var = tf.get_variable(name=\"up_filter\", initializer=init,\n",
        "                        shape=weights.shape)\n",
        "  return var\n",
        "\n",
        "def upscore_layer(x, shape, num_classes, name, ksize, stride):\n",
        "  \"\"\"transposed convolution filter to learn upsampling filter values.\n",
        "  Given a feature map x, initialize a bilinear interpolation filter with\n",
        "  given shape to upsample the map based on the given stride.\n",
        "  \n",
        "  this filter values are trained and updated in the current computation graph.\n",
        "  \"\"\"   \n",
        "  strides = [1, stride, stride, 1]\n",
        "  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "    in_features = x.get_shape()[3].value\n",
        "    if shape is None:\n",
        "      in_shape = tf.shape(x)\n",
        "      h = ((in_shape[1] - 1) * stride) + 1\n",
        "      w = ((in_shape[2] - 1) * stride) + 1\n",
        "      new_shape = [in_shape[0], h, w, num_classes]\n",
        "    else:\n",
        "      new_shape = [shape[0], shape[1], shape[2], num_classes]\n",
        "    \n",
        "    output_shape = tf.stack(new_shape)\n",
        "    f_shape = [ksize, ksize, num_classes, in_features]\n",
        "    num_input = ksize * ksize * in_features / stride\n",
        "    stddev = (2 / num_input)**0.5\n",
        "    weights = get_deconv_filter(f_shape)\n",
        "    deconv = tf.nn.conv2d_transpose(x, weights, output_shape, strides = strides, padding='SAME')\n",
        "    return deconv\n",
        "\n",
        "def score_layer(x, name, num_classes, stddev = 0.001): \n",
        "  \"\"\"receives a feature map and trains a linear scoring filter Wx+b\n",
        "  \n",
        "  this result with a new feature map with a consistent shape to be fused (per-pixel addition)\n",
        "  with the corresponding upsampling result from the same input feature map x.\n",
        "  \"\"\"\n",
        "  with tf.variable_scope(name, reuse=tf.AUTO_REUSE) as scope:\n",
        "    # get number of input channels\n",
        "    in_features = x.get_shape()[3].value\n",
        "    shape = [1, 1, in_features, num_classes]\n",
        "    w_decay = 5e-4\n",
        "    init = tf.truncated_normal_initializer(stddev = stddev)\n",
        "    weights = tf.get_variable(\"weights\", shape = shape, initializer = init)\n",
        "    collection_name = tf.GraphKeys.REGULARIZATION_LOSSES\n",
        "\n",
        "    if not tf.get_variable_scope().reuse:\n",
        "      weight_decay = tf.multiply(tf.nn.l2_loss(weights), w_decay, name='weight_loss')\n",
        "      tf.add_to_collection(collection_name, weight_decay)\n",
        "\n",
        "    conv = tf.nn.conv2d(x, weights, [1, 1, 1, 1], padding='SAME')\n",
        "    \n",
        "    # Apply bias\n",
        "    initializer = tf.constant_initializer(0.0)\n",
        "    conv_biases = tf.get_variable(name='biases', shape=[num_classes],initializer=initializer)\n",
        "    bias = tf.nn.bias_add(conv, conv_biases)\n",
        "    \n",
        "    return bias     \n",
        "      \n",
        "\n",
        "def softmax_cross_entropy(logits, labels, num_classes):\n",
        "  \"\"\"Calculate the loss from the logits and the labels.\n",
        "    Args:\n",
        "      logits: tensor, float - [N, H, W, num_classes].\n",
        "          Use upscore32 as logits.\n",
        "      labels: Labels tensor, int32 - [N, H, W, num_classes].\n",
        "          The ground truth of your data.\n",
        "    Returns:\n",
        "      loss: Loss tensor of type float.\n",
        "  \"\"\"\n",
        "  with tf.name_scope('softmax_ce_loss'):\n",
        "    logits = tf.reshape(logits, (-1, num_classes))\n",
        "    epsilon = tf.constant(value=1e-4)\n",
        "    labels = tf.to_float(tf.reshape(labels, (-1, num_classes)))\n",
        "    softmax = tf.nn.softmax(logits) + epsilon\n",
        "    cross_entropy = -tf.reduce_sum(labels * tf.log(softmax), \n",
        "                                   reduction_indices=[1])\n",
        "    \n",
        "    cross_entropy_mean = tf.reduce_mean(cross_entropy,\n",
        "                                        name='xentropy_mean')\n",
        "    \n",
        "    _loss = cross_entropy_mean + tf.add_n(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
        "    \n",
        "    tf.add_to_collection(tf.GraphKeys.LOSSES, _loss) \n",
        "    \n",
        "    return _loss\n",
        "  \n",
        "  \n",
        "def sigmoid_cross_entropy(logits, labels, num_classes):\n",
        "  \"\"\"Calculate the loss from the logits and the labels.\n",
        "    Args:\n",
        "      logits: tensor, float - [N, H, W, num_classes].\n",
        "          Use upscore32 as logits.\n",
        "      labels: Labels tensor, int32 - [N, H, W, num_classes].\n",
        "          The ground truth of your data.\n",
        "    Returns:\n",
        "      loss: Loss tensor of type float.\n",
        "  \"\"\"\n",
        "  with tf.name_scope('sigmoid_ce_loss'):\n",
        "    \n",
        "    logits = tf.reshape(logits, (-1, num_classes))\n",
        "    labels = tf.reshape(labels, (-1, num_classes))\n",
        "    \n",
        "    return tf.losses.sigmoid_cross_entropy(labels, logits)\n",
        "  \n",
        "  \n",
        "def inference(features, labels, params):\n",
        "  \n",
        "  num_classes=params['num_classes']\n",
        "  \n",
        "  # output_stride denotes the rate of downsampling in the resnet network,i.e.,\n",
        "  # 32 results with a feature map with a 1/32 downsampling rate such as,\n",
        "  # (224,224) input is decreased to (8,8) resolution. \n",
        "  # Then, the rest of the code starts upsampling from this output, until reaching\n",
        "  # the input resolution.\n",
        "  with slim.arg_scope(resnet_v1.resnet_arg_scope()):\n",
        "    net, end_points = resnet_v1.resnet_v1_50(features[\"image\"],\n",
        "                                             global_pool=False, \n",
        "                                             output_stride=32)\n",
        "    \n",
        "    scale5 = net\n",
        "    scale4 = end_points['resnet_v1_50/block3/unit_5/bottleneck_v1']\n",
        "    scale3 = end_points['resnet_v1_50/block2/unit_3/bottleneck_v1']\n",
        "    scale2 = end_points['resnet_v1_50/block1/unit_2/bottleneck_v1']\n",
        "    input_x = features[\"image\"]\n",
        "            \n",
        "      # stride=32\n",
        "      #resnet_v1_50/block3/unit_5/bottleneck_v1 (1, 15, 15, 1024)\n",
        "      #net.shape: (1, 8, 8, 2048)  \n",
        "      #resnet_v1_50/block2/unit_3/bottleneck_v1 (1, 29, 29, 512)\n",
        "      #resnet_v1_50/block1/unit_2/bottleneck_v1 (1, 57, 57, 256)\n",
        "      #resnet_v1_50/conv1 (1, 113, 113, 64)\n",
        "      \n",
        "  with tf.variable_scope('scale_fcn'):\n",
        "    #upscore2 = upscore_layer(scale5, shape = tf.shape(scale4), num_classes = num_classes, name = \"upscore2\", ksize = 4, stride = 2) \n",
        "    #score_scale4 = score_layer(scale4, \"score_scale4\", num_classes = num_classes)\n",
        "    #fuse_scale4 = tf.add(upscore2, score_scale4)\n",
        "      \n",
        "    #upscore4 = upscore_layer(fuse_scale4, shape = tf.shape(scale3), num_classes = num_classes, name = \"upscore4\", ksize = 4, stride = 2) \n",
        "    #score_scale3 = score_layer(scale3, \"score_scale3\", num_classes = num_classes)\n",
        "    #fuse_scale3 = tf.add(upscore4, score_scale3)\n",
        "      \n",
        "    #upscore8 = upscore_layer(fuse_scale3, shape = tf.shape(scale2), num_classes = num_classes, name = \"upscore8\", ksize = 4, stride = 2) \n",
        "    #score_scale2 = score_layer(scale2, \"score_scale2\", num_classes = num_classes)\n",
        "    #fuse_scale2 = tf.add(upscore8, score_scale2)\n",
        "    \n",
        "    #upscore32 = upscore_layer(fuse_scale2, shape = tf.shape(input_x), num_classes = num_classes, name = \"upscore32\", ksize = 8, stride = 4)\n",
        "      \n",
        "    #upscore32 = upscore_layer(upscore8, shape = tf.shape(input_x), num_classes = num_classes, name = \"upscore32\", ksize = 8, stride = 4)\n",
        "    \n",
        "    \n",
        "    score_scale5 = score_layer(scale5, \"score_scale5\", num_classes = num_classes) \n",
        "    upscore_scale5 =  upscore_layer(score_scale5, shape = tf.shape(scale4), num_classes = num_classes, name = \"upscore_scale5\", ksize = 4, stride = 2) \n",
        "    \n",
        "    score_scale4 = score_layer(scale4, \"score_scale4\", num_classes = num_classes)\n",
        "    fuse_scale4 = tf.add(upscore_scale5, score_scale4)\n",
        "      \n",
        "    upscore_fuse4 = upscore_layer(fuse_scale4, shape = tf.shape(scale3), num_classes = num_classes, name = \"upscore_fuse4\", ksize = 4, stride = 2) \n",
        "    \n",
        "    score_scale3 = score_layer(scale3, \"score_scale3\", num_classes = num_classes)\n",
        "    fuse_scale3 = tf.add(upscore_fuse4, score_scale3)\n",
        "      \n",
        "    upscore_fuse3 = upscore_layer(fuse_scale3, shape = tf.shape(input_x), num_classes = num_classes, name = \"upscore_fuse3\", ksize = 16, stride = 8) \n",
        "\n",
        "    pred_up = tf.argmax(upscore_fuse3, axis = 3)\n",
        "    pred = tf.expand_dims(pred_up, dim = 3, name='pred')     \n",
        "      \n",
        "  # Using tf.losses, any loss is added to the tf.GraphKeys.LOSSES collection\n",
        "  # We can then call the total loss easily    \n",
        "\n",
        "  sess = tf.Session()\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  sess.run(tf.local_variables_initializer())\n",
        "  print(sess.run(tf.shape(features[\"image\"])))\n",
        "  print(sess.run(tf.shape(upscore_fuse3)))\n",
        "  print(sess.run(tf.shape(labels[\"label\"])))\n",
        "  sess.close()\n",
        "    \n",
        "  tf.losses.sparse_softmax_cross_entropy(labels=labels[\"label\"], logits=upscore_fuse3)\n",
        "  loss = tf.losses.get_total_loss()\n",
        "  \n",
        "  ## Compute evaluation metrics.\n",
        "  # compute mean intersection over union, which corresponds to JA metric in the paper.\n",
        "  accuracy = tf.metrics.mean_iou(labels=tf.reshape(tf.argmax(labels[\"label\"],axis=2), [-1]),\n",
        "                                 num_classes=2,\n",
        "                                 predictions=tf.to_int32(tf.reshape(pred_up, [-1])),name=\"acc_op\")\n",
        "  \n",
        "  \n",
        "  ## SOFTMAX CROSS ENTROPY ##\n",
        "  #loss = softmax_cross_entropy(logits=tf.to_float(upscore32), labels=labels[\"label\"], num_classes=num_classes)\n",
        "\n",
        "  \n",
        "  ## SIGMOID CROSS ENTROPY  ##\n",
        "  #loss = sigmoid_cross_entropy(logits=tf.to_float(upscore32), \n",
        "  #                             labels=labels[\"label\"], \n",
        "  #                             num_classes=num_classes)\n",
        "\n",
        "  #accuracy = tf.metrics.mean_iou(\n",
        "   #   labels=tf.reshape(tf.argmax(labels[\"label\"],axis=2), [-1]), \n",
        "    #  num_classes=2, \n",
        "     # predictions=tf.to_int32(tf.reshape(tf.argmax(upscore32,axis=2), [-1])), name=\"acc_op\")\n",
        "  ############################\n",
        "  \n",
        "    \n",
        "  tf.summary.scalar('accuracy', accuracy[0])\n",
        "  \n",
        "  global_step = tf.train.get_or_create_global_step()     \n",
        "      \n",
        "  # set initial learning rate and \n",
        "  # scale it by 0.1 in every 3000 steps\n",
        "  # as stated in https://github.com/yulequan/melanoma-recognition/blob/master/segmentation/solver.prototxt\n",
        "  boundaries = [i*params['decay_steps'] for i in range(1, int(np.ceil(params['max_steps']/params['decay_steps']))) ]\n",
        "  boundaries[-1] = params['max_steps']\n",
        "  initial = [params['initial_learning_rate']]\n",
        "  values = initial + [params['initial_learning_rate']*(0.1**i) for i in range(1,len(boundaries)+1)]\n",
        "  lr = tf.train.piecewise_constant(global_step, boundaries, values)\n",
        "\n",
        "\n",
        "  # Variables that affect learning rate\n",
        "  var_resnet_batchnorm = [var for var in tf.trainable_variables() if ('conv1/BatchNorm' in var.name or 'conv2/BatchNorm' in var.name or 'conv3/BatchNorm' in var.name)] \n",
        "  \n",
        "  var_upscale = [var for var in tf.trainable_variables() if 'score' in var.name]\n",
        "  \n",
        "  var_rest = [var for var in tf.trainable_variables() if var.name not in var_resnet_batchnorm+var_upscale]\n",
        "  \n",
        "  # this is as stated in the paper and prototxt file,\n",
        "  # https://github.com/yulequan/melanoma-recognition/blob/master/segmentation/ResNet-50-f8s-skin-train-val.prototxt\n",
        "  # batchnorm filters placed just after each convolutional layer in each resnet block, are not trained.\n",
        "  # so we set zero learning for these variables\n",
        "  #opt1 = tf.train.GradientDescentOptimizer(0)\n",
        "  \n",
        "  # this is also due to the prototxt file and the paper,\n",
        "  # scoring and upsampling filters receive 0.1 * learning rate\n",
        "  # https://github.com/yulequan/melanoma-recognition/blob/master/segmentation/ResNet-50-f8s-skin-train-val.prototxt\n",
        "  opt2 = tf.train.GradientDescentOptimizer(lr*0.1)\n",
        "  \n",
        "  # rest of the variables receive the current learning rate\n",
        "  opt3 = tf.train.GradientDescentOptimizer(lr)\n",
        "  \n",
        "  # gradient op: obtain the gradients with loss and given variables\n",
        "  #grads = tf.gradients(loss, var_resnet_batchnorm + var_upscale + var_rest)\n",
        "  grads = tf.gradients(loss, var_upscale + var_rest)\n",
        "  \n",
        "  # grads for the first set of variables, currently has no effect due to zero learning rate.\n",
        "  #grads1 = grads[:len(var_resnet_batchnorm)]\n",
        "  \n",
        "  # grads for scoring and upsampling filters. Will get updated based on 0.1*learning_rate\n",
        "  #grads2 = grads[len(var_resnet_batchnorm):len(var_resnet_batchnorm)+len(var_upscale)]\n",
        "  grads2 = grads[:len(var_upscale)]\n",
        "  \n",
        "  # grads for rest of the variables\n",
        "  #grads3 = grads[len(var_resnet_batchnorm)+len(var_upscale):]\n",
        "  grads3 = grads[len(var_upscale):]\n",
        "  \n",
        "  #train_op1 = opt1.apply_gradients(zip(grads1, var_resnet_batchnorm), global_step=global_step)\n",
        "  train_op2 = opt2.apply_gradients(zip(grads2, var_upscale), global_step=global_step)\n",
        "  train_op3 = opt3.apply_gradients(zip(grads3, var_rest), global_step=global_step)\n",
        "  \n",
        "  #train_op = tf.group(train_op1, train_op2, train_op3)\n",
        "  train_op = tf.group(train_op2, train_op3)\n",
        "\n",
        "\n",
        "  ##### exponential weight decaying for learning rate #####\n",
        "#  lr = tf.train.exponential_decay(params['initial_learning_rate'],\n",
        "#                                 global_step,\n",
        "#                                params['decay_steps'],\n",
        "#                               params['learning_rate_decay_factor'],\n",
        "#                              staircase=True)\n",
        "#  \n",
        "#  train_op = tf.train.GradientDescentOptimizer(lr).minimize(loss, global_step=global_step) \n",
        "  ##### exponential weight decaying for learning rate #####\n",
        "  \n",
        "      \n",
        "  return loss, accuracy[0], train_op\n",
        "      \n",
        "\n",
        "filename = 'melanoma_train.tfrecords'\n",
        "batch_size=1\n",
        "epochs=50\n",
        "save_model_path='./checkpoints'\n",
        "restore_ckpt_path='./resnet_v1_50.ckpt'\n",
        "initial_learning_rate=1e-3\n",
        "num_classes=2\n",
        "params = {'initial_learning_rate' : initial_learning_rate,\n",
        "          'learning_rate_decay_factor' : 0.96,\n",
        "          'num_classes' : num_classes,\n",
        "          'decay_steps' : 3000,\n",
        "          'max_steps' : 100000}\n",
        "  \n",
        "  \n",
        "features_op, labels_op = my_input_fn(filename, batch_size, epochs) \n",
        "ops = inference(features_op, labels_op, params)\n",
        "  \n",
        "  \n",
        "with tf.Session() as sess:\n",
        "  \n",
        "  exclude_restore = [var.name for var in tf.global_variables() if ('logits' in var.name or 'scale_fcn' in var.name) ] \n",
        "  \n",
        "  \n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  sess.run(tf.local_variables_initializer())\n",
        "  \n",
        "  variables_to_restore = slim.get_variables_to_restore(exclude=exclude_restore)\n",
        "  tf.train.init_from_checkpoint(restore_ckpt_path,\n",
        "                                {v.name.split(':')[0]: v for v in variables_to_restore})\n",
        "  \n",
        "  print('RESTORE COMPLETE!')\n",
        "  \n",
        "  saver = tf.train.Saver()\n",
        "  \n",
        "  train_step = 0\n",
        "  print_every = 100\n",
        "  while True:\n",
        "    try:\n",
        "      \n",
        "      #print(sess.run(labels_op))\n",
        "      \n",
        "      loss, acc, _ = sess.run(ops)\n",
        "\n",
        "      \n",
        "      train_step += 1\n",
        "      \n",
        "      print('training loss: {},  step: {}'.format(loss, train_step))\n",
        "      \n",
        "      if train_step % print_every == 0:\n",
        "        print('training mIOU: {},  step: {}'.format(acc, train_step))\n",
        "      \n",
        "      \n",
        "    except tf.errors.OutOfRangeError:\n",
        "      \n",
        "      print('Training finished. Saving the resulting model to {}'.format(save_model_path))\n",
        "      save_path = saver.save(sess, args.save_path)\n",
        "      \n",
        "      break  \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}